{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNGjNEn8Si8P2/GP7rWimEk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FernandaXdea/MachineLearning/blob/main/Python_para_Machine_Learning_na_Pr%C3%A1tica.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5Y4wWqT9Sdj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Utilizando a ferramenta Replit em nuvem\n",
        "[REPLIT LINK](https://replit.com/@fernandaXdea/)"
      ],
      "metadata": {
        "id": "nRasaSzwJ1w4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Tipos de variáveis para trabalhar com ML\n",
        "######**Inteiro (int):** Representa números inteiros, como 18 ou 2002.\n",
        "######**Ponto flutuante (float):** Representa números com casas decimais, como 1.75 ou 70.5.\n",
        "######**String (str):** Representa texto, como \"Fernanda\" ou \"Brasília\".\n",
        "######**Booleano (bool):**Representa valores lógicos, como True (verdadeiro) ou False (falso).\n",
        "######**Lista (list):** Armazena uma coleção ordenada e mutável de itens, como [1, 2, 3] ou [\"maçã\", \"banana\"].\n",
        "######**Tupla (tuple):**Armazena uma coleção ordenada e imutável de itens, como (10, 20) ou (\"azul\", \"vermelho\").\n",
        "######**Dicionário (dict):** Representa pares de chave-valor, como {\"nome\": \"Fernanda\", \"idade\": 18}.\n",
        "######**Conjunto (set):** Representa uma coleção de itens únicos, como {1, 2, 3} ou {\"a\", \"b\", \"c\"}.\n"
      ],
      "metadata": {
        "id": "h303NDNNNpO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inteiro\n",
        "idade = 18\n",
        "ano = int(2002)\n",
        "\n",
        "# Ponto flutuante\n",
        "altura = 1.75\n",
        "peso = float(70.5)\n",
        "\n",
        "# String\n",
        "nome = \"Fernanda\"\n",
        "cidade = str(\"Brasília\")\n",
        "\n",
        "# Booleano\n",
        "estudando = True\n",
        "trabalhando = bool(False)\n",
        "\n",
        "# Lista\n",
        "frutas = [\"maçã\", \"banana\", \"laranja\"]\n",
        "numeros = list([1, 2, 3, 4, 5])\n",
        "\n",
        "# Tupla\n",
        "coordenadas = (10, 20)\n",
        "cores = tuple((\"azul\", \"vermelho\", \"verde\"))\n",
        "\n",
        "# Dicionário\n",
        "pessoa = {\"nome\": \"Fernanda\", \"idade\": 18}\n",
        "produto = dict(nome=\"Notebook\", preco=4500)\n",
        "\n",
        "# Conjunto\n",
        "numeros_unicos = {1, 2, 3, 4}\n",
        "letras = set([\"a\", \"b\", \"c\", \"a\"])\n",
        "\n",
        "# Exibindo os tipos\n",
        "print(\"Tipos das variáveis:\")\n",
        "print(type(idade))           # <class 'int'>\n",
        "print(type(altura))          # <class 'float'>\n",
        "print(type(nome))            # <class 'str'>\n",
        "print(type(estudando))       # <class 'bool'>\n",
        "print(type(frutas))          # <class 'list'>\n",
        "print(type(coordenadas))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnO31LeSQUht",
        "outputId": "f20ca2bb-0b8f-4b94-a08d-8891709c7ffd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tipos das variáveis:\n",
            "<class 'int'>\n",
            "<class 'float'>\n",
            "<class 'str'>\n",
            "<class 'bool'>\n",
            "<class 'list'>\n",
            "<class 'tuple'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Estruturas condicionais em ML"
      ],
      "metadata": {
        "id": "RiIdCqGcU21E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1z0qEpeTNJaW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##Principais condições ou conceitos de Machine Learning\n",
        "#####**Overfitting:** Quando o modelo se ajusta muito bem aos dados de treinamento, mas falha em generalizar para novos dados.\n",
        "\n",
        "Palavra: Excesso.\n",
        "#####**Underfitting:** Quando o modelo é muito simples para capturar os padrões dos dados, resultando em baixo desempenho.\n",
        "\n",
        "Palavra: Insuficiência.\n",
        "#####**Generalização:** A capacidade de um modelo de performar bem em novos dados não vistos durante o treinamento.\n",
        "\n",
        "Palavra: Adaptação.\n",
        "#####**Regularização:** Técnica usada para reduzir o overfitting ao penalizar modelos complexos.\n",
        "\n",
        "Palavra: Simplificação.\n",
        "#####**Gradient Descent:** Método iterativo usado para minimizar a função de perda ajustando os pesos do modelo.\n",
        "\n",
        "Palavra: Otimização.\n",
        "#####**Learning Rate:** Taxa que controla o tamanho dos ajustes nos pesos durante o treinamento.\n",
        "\n",
        "Palavra: Velocidade.\n",
        "#####**Epoch:** Uma passagem completa por todo o conjunto de dados durante o treinamento do modelo.\n",
        "\n",
        "Palavra: Iteração.\n",
        "#####**Batch Size: **O número de amostras processadas antes da atualização dos pesos no treinamento.\n",
        "\n",
        "Palavra: Lote.\n",
        "#####**Bias:** Erro causado por suposições incorretas no modelo, resultando em underfitting.\n",
        "\n",
        "Palavra: Tendência.\n",
        "#####**Variance:** Sensibilidade do modelo a pequenas variações nos dados de treinamento, resultando em overfitting.\n",
        "\n",
        "Palavra: Instabilidade.\n",
        "#####**Feature Scaling:** Técnica para normalizar ou padronizar os dados para que tenham a mesma escala.\n",
        "\n",
        "Palavra: Normalização.\n",
        "#####**Hyperparameter Tuning:** Processo de ajustar os parâmetros do modelo para otimizar seu desempenho.\n",
        "\n",
        "Palavra: Ajuste.\n",
        "#####**Loss Function:** Mede a diferença entre a previsão do modelo e o valor real.\n",
        "\n",
        "Palavra: Erro.\n",
        "#####**Accuracy:** Métrica que avalia a porcentagem de previsões corretas feitas pelo modelo.\n",
        "Palavra: Precisão.\n",
        "#####**Cross-Validation:** Técnica para avaliar o desempenho do modelo dividindo os dados em partes para treinamento e validação.\n",
        "Palavra: Validação."
      ],
      "metadata": {
        "id": "Jx_2p1_8RafP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Overfitting\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import load_iris  # Exemplo com o dataset Iris\n",
        "\n",
        "# Carregar o dataset Iris\n",
        "data = load_iris()\n",
        "X = data.data  # Dados de entrada\n",
        "y = data.target  # Rótulos\n",
        "\n",
        "# Dividir os dados em treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Criar o modelo e treinar\n",
        "model = DecisionTreeClassifier(max_depth=None)  # Sem limite de profundidade\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Avaliar o modelo\n",
        "print(\"Treino:\", model.score(X_train, y_train))\n",
        "print(\"Teste:\", model.score(X_test, y_test))  # Erro maior -> overfitting\n",
        "\n",
        "\n",
        "#Underfitting\n",
        "model = DecisionTreeClassifier(max_depth=1)  # Árvore rasa\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Treino:\", model.score(X_train, y_train))\n",
        "print(\"Teste:\", model.score(X_test, y_test))  # Desempenho ruim -> underfitting\n",
        "\n",
        "#Regularização\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "model = Ridge(alpha=1.0)  # Regularização com L2\n",
        "model.fit(X_train, y_train)\n",
        "print(\"Score:\", model.score(X_test, y_test))\n",
        "\n",
        "#Gradient Descent\n",
        "import numpy as np\n",
        "\n",
        "# Função de perda: erro quadrático médio\n",
        "def mse(y_true, y_pred):\n",
        "    return np.mean((y_true - y_pred) ** 2)\n",
        "\n",
        "# Gradiente descendente para um coeficiente w\n",
        "def gradient_descent(X, y, w, lr, epochs):\n",
        "    for _ in range(epochs):\n",
        "        gradient = -2 * np.dot(X.T, (y - np.dot(X, w))) / len(y)\n",
        "        w -= lr * gradient\n",
        "    return w\n",
        "\n",
        "#Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "#Cross-Validation\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "model = DecisionTreeClassifier()\n",
        "scores = cross_val_score(model, X, y, cv=5)  # 5-fold\n",
        "print(\"Scores:\", scores)\n",
        "\n",
        "#Bias e Variance\n",
        "model_low_bias = DecisionTreeClassifier(max_depth=None)  # Alta variância\n",
        "model_high_bias = DecisionTreeClassifier(max_depth=2)    # Alta bias\n",
        "\n",
        "#Loss Function\n",
        "import numpy as np\n",
        "\n",
        "y_true = np.array([1, 0, 1, 0])\n",
        "y_pred = np.array([0.8, 0.1, 0.6, 0.2])\n",
        "\n",
        "# Erro quadrático médio\n",
        "mse = np.mean((y_true - y_pred) ** 2)\n",
        "print(\"MSE:\", mse)\n",
        "\n",
        "#Accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_true = [0, 1, 1, 0]\n",
        "y_pred = [0, 1, 0, 0]\n",
        "print(\"Acurácia:\", accuracy_score(y_true, y_pred))\n",
        "\n",
        "#Hyperparameter Tuning\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {'max_depth': [2, 4, 6, 8]}\n",
        "model = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=5)\n",
        "model.fit(X, y)\n",
        "\n",
        "print(\"Melhor parâmetro:\", model.best_params_)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSt6U9o_TfBE",
        "outputId": "1ff309d5-bff7-439a-c4ff-ad84c42cd5e3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treino: 1.0\n",
            "Teste: 0.9666666666666667\n",
            "Treino: 0.6583333333333333\n",
            "Teste: 0.7\n",
            "Score: 0.9331633276574093\n",
            "Scores: [0.96666667 0.96666667 0.9        0.96666667 1.        ]\n",
            "MSE: 0.0625\n",
            "Acurácia: 0.75\n",
            "Melhor parâmetro: {'max_depth': 8}\n"
          ]
        }
      ]
    }
  ]
}